{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyqcnIL7RXIOCPleAKYm+l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XenoicZ/PointCloud/blob/main/test_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MZSjSpIEBJ3N"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torch_geometric\n",
        "!pip install uproot\n",
        "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cpu.html\n",
        "import torch\n",
        "import uproot\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# to-do: make new directory\n",
        "#        assign directory with variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Batch"
      ],
      "metadata": {
        "id": "99cupWgg8PvX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "pi0_files = sorted(glob('/content/drive/MyDrive/ml4pion/data/onetrack_multicluster/pi0_files/'+'*.npy'))\n",
        "pion_files = sorted(glob('/content/drive/MyDrive/ml4pion/data/onetrack_multicluster/pion_files/'+'*.npy'))"
      ],
      "metadata": {
        "id": "HERTf1OAlksK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = uproot.open('/content/drive/MyDrive/ml4pion/RhoDeltaPion/Samp_data/Rho/user.angerami.29450173.OutputStream._000001.root')['CellGeo']\n",
        "data['cell_geo_prevInPhi'].array(library='np')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duwGVRVlNGPt",
        "outputId": "d1fb1ca0-d7cf-4fcb-a36a-572376c86e9d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([array([    63,      0,      1, ..., 187641, 187642, 187643], dtype=int32)],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import uproot\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.data import Dataset, Data\n",
        "\n",
        "torch.set_default_dtype(torch.float32)\n",
        "\n",
        "node_feature_names = ['cluster_cell_E', 'cell_geo_sampling', 'cell_geo_eta', \n",
        "                      'cell_geo_phi', 'cell_geo_rPerp', 'cell_geo_deta', 'cell_geo_dphi']\n",
        "edge_feature_names = ['cell_geo_prevInPhi', 'cell_geo_nextInPhi',\n",
        "                      'cell_geo_prevInEta', 'cell_geo_nextInEta',\n",
        "                      'cell_geo_prevInSamp','cell_geo_nextInSamp',\n",
        "                      'cell_geo_prevSubDet','cell_geo_nextSubDet',\n",
        "                      'cell_geo_prevSuperCalo','cell_geo_nextSuperCalo']\n",
        "global_feature_names = ['cluster_E', 'trackPt', 'trackZ0', 'trackEta', 'trackPhi']\n",
        "\n",
        "cellGeo_data = uproot.open('/content/drive/MyDrive/ml4pion/RhoDeltaPion/Samp_data/Rho/user.angerami.29450173.OutputStream._000001.root')['CellGeo']\n",
        "cellGeo_ID = cellGeo_data['cell_geo_ID'].array()[0]\n",
        "sorter = np.argsort(cellGeo_ID)\n",
        "\n",
        "class GraphDataset(Dataset):\n",
        "    def __init__(self, root, i_file,\n",
        "                 transform=None, pre_transform=None, pre_filter=None):\n",
        "      \n",
        "        self.i_file = i_file\n",
        "        self.cellGeo_data = uproot.open('/content/drive/MyDrive/ml4pion/RhoDeltaPion/Samp_data/Rho/user.angerami.29450173.OutputStream._000001.root')['CellGeo']\n",
        "        self.cellGeo_ID = self.cellGeo_data['cell_geo_ID'].array()[0]\n",
        "        self.sorter = np.argsort(self.cellGeo_ID)\n",
        "        self.edgeFeatureNames = self.cellGeo_data.keys()[9:]\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "        \n",
        "        # to-do: index by file\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return 'user.angerami.29450173.OutputStream._' + format(self.i_file, '06d') + '.root'\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return 'test.pt'\n",
        "\n",
        "    def download(self):\n",
        "        print('raw_file not found warning')\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        self.N_events = 0\n",
        "        raw_path = self.raw_paths[0]\n",
        "\n",
        "        # Read data from `raw_path`.\n",
        "        \n",
        "        event_file = uproot.open(raw_path)['EventTree']\n",
        "        N_events = len(event_file[0].array())\n",
        "        processed_data = []\n",
        "\n",
        "        for i_event in tqdm(range(N_events)):\n",
        "            if event_file['nCluster'].array()[i_event] != 2 or event_file['nTrack'].array()[i_event] != 1:\n",
        "                continue\n",
        "            node_features, N_nodes, cell_IDmap = self._get_node_features(event_file, i_event)\n",
        "            edge_features, edge_index = self._get_edge_features(N_nodes, cell_IDmap)\n",
        "            global_features = self._get_global_features(event_file, i_event)\n",
        "\n",
        "            processed_data.append(Data(x=node_features, edge_attr=edge_features,\n",
        "                                       edge_index=edge_index, y=global_features, dtype=torch.float32))\n",
        "            \n",
        "        torch.save(processed_data, osp.join(self.processed_dir, f'data_{self.i_file}.pt'))\n",
        "        self.N_events = len(processed_data)\n",
        "        \n",
        "\n",
        "    def len(self):\n",
        "        return self.N_events\n",
        "\n",
        "    def get(self, i_event):\n",
        "        data = torch.load(osp.join(self.processed_dir, f'data_{self.i_file}.pt'))[i_event]\n",
        "        return data\n",
        "\n",
        "    def _get_node_features(self, event_file, i_event):\n",
        "        \n",
        "        cell_IDs = event_file['cluster_cell_ID'].array()[i_event][0] ### to-do: genelize to multiple clusters\n",
        "        cell_IDmap = self.sorter[np.searchsorted(self.cellGeo_ID, cell_IDs, sorter=self.sorter)]\n",
        "        N_nodes = len(cell_IDs)\n",
        "\n",
        "        node_features = torch.zeros((N_nodes, len(node_feature_names)))\n",
        "        \n",
        "        temp = np.log10(event_file['cluster_cell_E'].array(library='np')[i_event][0])\n",
        "        node_features[:,0] = torch.from_numpy(temp)\n",
        "        \n",
        "        for i, name in enumerate(node_feature_names[1:]):\n",
        "            temp = cellGeo_data[name].array(library='np')[0][cell_IDmap].astype(float)\n",
        "            node_features[:,i+1] = torch.from_numpy(temp)\n",
        "        \n",
        "        return node_features, N_nodes, cell_IDmap\n",
        "\n",
        "    def _get_edge_features(self, N_nodes, cell_IDmap):\n",
        "        edge_index = np.zeros((N_nodes, len(self.edgeFeatureNames)))\n",
        "        for i, name in enumerate(edge_feature_names):\n",
        "            edge_index[:,i] = self.cellGeo_data[name].array(library='np')[0][cell_IDmap]\n",
        "            mask = np.logical_not(np.isin(edge_index[:,i], cell_IDmap))\n",
        "            edge_index[mask,i] = np.nan\n",
        "\n",
        "        senders, edge_on_inds = np.nonzero(np.isin(edge_index, cell_IDmap))\n",
        "        \n",
        "        N_edges = len(senders)\n",
        "        edge_features = np.zeros((N_edges, len(self.edgeFeatureNames)))\n",
        "        edge_features[np.arange(N_edges), edge_on_inds] = 1\n",
        "\n",
        "        cell_IDmap_sorter = np.argsort(cell_IDmap)\n",
        "        rank = np.searchsorted(cell_IDmap, edge_index , sorter=cell_IDmap_sorter)\n",
        "        receivers = cell_IDmap_sorter[rank[rank!=N_nodes]]\n",
        "\n",
        "        return torch.tensor(edge_features, dtype=torch.float), torch.tensor([senders, receivers], dtype=torch.float)\n",
        "\n",
        "\n",
        "    def _get_global_features(self, event_file, i_event):\n",
        "        global_features = []\n",
        "        for name in global_feature_names:\n",
        "            global_features.append(event_file[name].array()[i_event][0])\n",
        "        global_features = torch.tensor(global_features, dtype=torch.float)\n",
        "        return global_features"
      ],
      "metadata": {
        "id": "g0-mpziCDPWH"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = GraphDataset('/content/drive/MyDrive/ml4pion/RhoDeltaPion/Samp_data/Rho', 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVNYrfxp6KxL",
        "outputId": "83f18b24-04f7-49f4-e9b7-16224fad5830"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datas =torch.utils.data.ConcatDataset([\n",
        "            GraphDataset('/content/drive/MyDrive/ml4pion/RhoDeltaPion/Samp_data/Rho', i)\\\n",
        "            for i in range( 1,2 )            \n",
        "    ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc3DmtpyPoqT",
        "outputId": "bf5c120b-b4d5-4d31-ce0a-9445644672f1"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "100%|██████████| 5000/5000 [07:51<00:00, 10.60it/s]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datas[0].edge_index.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep46pzZKgpRp",
        "outputId": "85729476-ea2b-4fa4-c4c0-ff8256ba07bb"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "loader = DataLoader(datas, batch_size=3, shuffle=False)\n",
        "for i, samp in enumerate(loader):\n",
        "    global_features = torch.reshape(samp.y, (3,5))\n",
        "    print(samp.y)\n",
        "    print(global_features)\n",
        "    #print(samp.batch[samp.edge_index[0]])\n",
        "    #print(samp.batch[samp.edge_index[1]])\n",
        "    x = samp.batch[samp.edge_index[1]]\n",
        "    print(model(samp.x, samp.edge_index, samp.edge_attr, global_features, samp.batch))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "V9hb0TIUrD4o",
        "outputId": "dcb7b15f-0616-4a81-8e5e-aad4e73cf5cb"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4.1431e+00,  3.5067e+00, -1.5764e+01, -1.6843e+00, -9.5085e-01,\n",
            "         1.3381e+03,  1.0181e+03, -3.2734e+01, -5.5517e-01,  1.4673e+00,\n",
            "         1.2889e+01,  1.2400e+00,  5.0983e+01,  2.1723e+00, -4.0360e-01])\n",
            "tensor([[ 4.1431e+00,  3.5067e+00, -1.5764e+01, -1.6843e+00, -9.5085e-01],\n",
            "        [ 1.3381e+03,  1.0181e+03, -3.2734e+01, -5.5517e-01,  1.4673e+00],\n",
            "        [ 1.2889e+01,  1.2400e+00,  5.0983e+01,  2.1723e+00, -4.0360e-01]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-04d417028d9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#print(samp.batch[samp.edge_index[0]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(samp.batch[samp.edge_index[1]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import MetaLayer\n",
        "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, BatchNorm1d\n",
        "from torch_scatter import scatter_mean\n",
        "\n",
        "torch.set_default_dtype(torch.float32)\n",
        "\n",
        "#inputs = np.array([7,10,5])\n",
        "global_size = 5\n",
        "edge_size = 10\n",
        "node_size = 7\n",
        "latent_size = 64\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        print('x: '+str(x.dtype))\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "class EdgeBlock(torch.nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(EdgeBlock, self).__init__()\n",
        "        self.edge_mlp = MLP(input_size*2+edge_size+global_size)\n",
        "\n",
        "    def forward(self, src, dest, edge_attr, u, batch):\n",
        "        print(src.size())\n",
        "        print(dest.size())\n",
        "        print(len(edge_attr))\n",
        "        print(u.size())\n",
        "        print(batch.size())\n",
        "        out = torch.cat([src, dest, edge_attr, u[batch]], 1)\n",
        "        print(out)\n",
        "        return self.edge_mlp(out)\n",
        "\n",
        "\n",
        "class GlobalBlock(torch.nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GlobalBlock, self).__init__()\n",
        "        \n",
        "        self.global_mlp = MLP(input_size+node_size) ## \n",
        "        \n",
        "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
        "\n",
        "        out = torch.cat([u,scatter_mean(x, batch, dim=0)], dim=1)\n",
        "\n",
        "        return self.global_mlp(out)\n",
        "\n",
        "class GraphBlock(torch.nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(GraphBlock, self).__init__()\n",
        "        self.graph_block = MetaLayer(EdgeBlock(7), None, GlobalBlock(input_size))\n",
        "        #self.bn = BatchNorm1d(inputs)\n",
        "        \n",
        "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
        "        \n",
        "        #x = self.bn(x)\n",
        "        x, edge_attr, u = self.graph_block(x, edge_index, edge_attr, u, batch)\n",
        "\n",
        "        return edge_attr, u\n",
        "\n",
        "class GraphNetwork(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GraphNetwork, self).__init__()\n",
        "\n",
        "        self.block0 = GraphBlock(global_size)\n",
        "        self.block1 = GraphBlock(latent_size)\n",
        "        self.block2 = GraphBlock(latent_size)\n",
        "        self.block3 = GraphBlock(latent_size)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
        "        edge_attr, u = self.block0(x, edge_index, edge_attr, u, batch)\n",
        "\n",
        "        edge_attr, u = self.block1(x, edge_index, edge_attr, u, batch)\n",
        "\n",
        "        edge_attr, u = self.block2(x, edge_index, edge_attr, u, batch)\n",
        "\n",
        "        edge_attr, u = self.block3(x, edge_index, edge_attr, u, batch)\n",
        "        '''\n",
        "        print(u)\n",
        "        x, edge_attr, u = self.block0(x, edge_index, edge_attr, u, batch)\n",
        "        print(u)\n",
        "        x, edge_attr, u = self.block1(x, edge_index, edge_attr, u, batch)\n",
        "        print(u)\n",
        "        x, edge_attr, u = self.block2(x, edge_index, edge_attr, u, batch)\n",
        "        print(u)\n",
        "        x, edge_attr, u = self.block3(x, edge_index, edge_attr, u, batch)\n",
        "        '''\n",
        "        return u"
      ],
      "metadata": {
        "id": "GbSyuug915zs"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphNetwork()"
      ],
      "metadata": {
        "id": "JEv0YLManim5"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(param.dtype)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2zDieVRyKeT",
        "outputId": "ca433e69-361f-42bf-c714-b2f1f6a72c81"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(model.named_parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MB4okMapNBz",
        "outputId": "5f67367a-f551-40b4-a97b-2d078192db22"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__del__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__name__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__next__',\n",
              " '__qualname__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " 'close',\n",
              " 'gi_code',\n",
              " 'gi_frame',\n",
              " 'gi_running',\n",
              " 'gi_yieldfrom',\n",
              " 'send',\n",
              " 'throw']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8gChW8OtiNM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}